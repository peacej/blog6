---
Title: Creative AI
---

AI-generated art/games/music is the coolest thing I have ever encountered in my life.

Since January 2023, as the founder and leader of the Japan office of Stability AI, I talked a lot about Stable Diffusion and generative AI in public. 

For example, [here is a 6-minute special about Stable Diffusion on TBS](https://www.youtube.com/watch?v=2Jmv22jbMPc), the Japanese TV station (June 2023). 

While at Stability AI, I co-led the development of cool interactive AI art projects...

...[with Honda](https://chizaizukan.com/property/honda-dream-loop-ai/), allowing users to generate their "dream vehicle" and make it float on a giant curved screen at Japan Mobility Show:

![image]({static}/images/honda1.webp)
![image]({static}/images/honda2.webp)


...[with Asahi Beer](https://www.asahibeer.co.jp/news/2023/0926.html), allowing users to upload a photo of themselves holding the newest Asahi beer can and turning it into art reflecting their mood:

![image]({static}/images/asahibeer.jpg)


Check out [my curated list of AI art/music resources/tools](https://docs.google.com/document/d/1-P58p-5yx8OXE0_0RN_D5Zg3lGqYQ88xtxOXClX5c_I/edit#). It includes both non-technical resources that anyone can use to generate art and technical resources on the math and ML stuff (maybe out of date).

Also, see my [AI art blog posts](https://jerrychi.com/tag/ai-art.html).

In 2022 Aug, I gave a talk on text-to-image generative models for Machine Learning Tokyo ([slides](https://docs.google.com/presentation/d/1iTpMFJR6AtcwcOCehFBabYPUuMSq1HglcRyZgjGXOR8/edit#slide=id.p)) ([video](https://www.youtube.com/watch?v=SdahlzTVqVc)).

In 2022 Oct, I gave a [short talk on AI Art NFTs](https://docs.google.com/presentation/d/11HRdJKUjmtrK0AgqKcq6eULrKwbHWEfK92PmzaBbfOA/edit#slide=id.g179e6f68ae5_0_0).


Below is an image generated by a Diffusion Transformer model called Tsubaki, trained from scratch by my team in 2025.
![image]({static}/images/pixai-tsubaki-dancing.png)


Below are some of my favorite outputs curated from my use of DALL·E 2 and Stable Diffusion, mostly during 2022.

"A very very cute drawing of three Chinese zodiac animals by Takashi Murakami" (DALL·E 2)

![image]({static}/images/DALL·E 2022-06-17 16.24.16 - A very very cute drawing of three Chinese zodiac animals by Takashi Murakami .png)

"Candid photo of Totoro, photographed by Annie Leibovitz" (DALL·E 2)

![image]({static}/images/DALL·E 2022-11-07 15.54.28 - Candid photo of Totoro, photographed by Annie Leibovitz.png)

"A super saiyan jellyfish, 8k digital art" (DALL·E 2)

![image]({static}/images/DALL·E 2022-07-24 16.20.19 - A super saiyan jellyfish, 8k digital art.png)

"A super saiyan cute kpop girl with blue hair surrounded in flames, 8k digital art" (DALL·E 2)

![image]({static}/images/DALL·E 2022-07-20 09.02.42 - A super saiyan cute kpop girl with blue hair surrounded in flames, 8k digital art .png)

"rusty metal cyborg with a fiery dark portal to hades in the chest". I first inputted a photo of me into animefilter.com, then uploaded my anime-style face into DALL-E 2 while erasing the white space around it. 

![image]({static}/images/DALL·E 2022-07-24 21.42.01 - rusty metal cyborg with a fiery dark portal to hades in the chest.png)

"glamorous kpop idol partially made of intricate steampunk cyborg parts posing for a photo, 35mm film" (DALL·E 2)

![image]({static}/images/DALL·E 2022-06-22 21.05.23 - glamorous kpop idol partially made of intricate steampunk cyborg parts posing for a photo, 35mm film .png)

"A grandiose heavenly xianxia city in the clouds, 8k digital art" ([xianxia is 仙俠](https://en.wikipedia.org/wiki/Xianxia_(genre)), a Chinese fantasy genre) (DALL·E 2)  

![image]({static}/images/DALL·E 2022-07-29 21.18.53 - A grandiose heavenly xianxia city in the clouds, 8k digital art.png)

"Isometric view illustration of a sprawling cyberpunk metropolis, bustling Tokyo cityscape, futuristic scifi architecture in the year 2100, nighttime satellite photo, synthwave art by james gilleard, bruce pennington, unreal engine" (Stable Diffusion)

![image]({static}/images/311503951_10106693626854923_2220319810559106406_n.jpeg)

“Pop art of daft punk at a vaporwave neon futuristic cyberpunk Tokyo bustling street at night cyberart by liam wong, rendered in octane, 3d render, trending on cgsociety, blender 3d” (Stable Diffusion)

![image]({static}/images/4078242513_Pop_art_of_daft_punk_at_a_vaporwave_neon_futuristic_cyberpunk_Tokyo__bustling_street_at_night_cyberart_by_liam_wong__rendered_in_octane__3d_render__trending_on_cgsociety__blender_3d.png)

To generate a video of changing anime faces, I interpolated in a custom autoencoder latent space of the pretrained VAE latent space of the [Waifu Diffusion](https://github.com/harubaru/waifu-diffusion) model (fine-tuned from [Stable Diffusion](https://github.com/CompVis/stable-diffusion)). I was going to publish a paper about this but became too busy..

<div class="youtube" align="center">
<iframe width="512" height="512" src="https://www.youtube.com/embed/lkdqfyDCK70" frameborder="0"></iframe>
</div>
