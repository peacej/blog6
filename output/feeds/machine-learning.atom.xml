<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jerry Chi's website - machine learning</title><link href="https://jerrychi.com/" rel="alternate"></link><link href="https://jerrychi.com/feeds/machine-learning.atom.xml" rel="self"></link><id>https://jerrychi.com/</id><updated>2020-06-12T00:00:00+09:00</updated><subtitle>Jerry Chi&lt;BR&gt;Data Scientist in Tokyo</subtitle><entry><title>How Machine Learning May Save Humanity</title><link href="https://jerrychi.com/how-machine-learning-may-save-humanity.html" rel="alternate"></link><published>2020-06-12T00:00:00+09:00</published><updated>2020-06-12T00:00:00+09:00</updated><author><name>Jerry Chi</name></author><id>tag:jerrychi.com,2020-06-12:/how-machine-learning-may-save-humanity.html</id><summary type="html">&lt;p&gt;¬∑4 min read&lt;/p&gt;
&lt;p&gt;I think humanity will end eventually (whether it takes hundreds or thousands of years). So what‚Äôll we do when the end is near? We‚Äôd want to leave our legacy; in other words, &lt;strong&gt;we‚Äôd want to save humanity‚Äôs knowledge and history as data and ‚Ä¶&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;¬∑4 min read&lt;/p&gt;
&lt;p&gt;I think humanity will end eventually (whether it takes hundreds or thousands of years). So what‚Äôll we do when the end is near? We‚Äôd want to leave our legacy; in other words, &lt;strong&gt;we‚Äôd want to save humanity‚Äôs knowledge and history as data and send it into space, hoping that aliens somewhere will receive it&lt;/strong&gt;. That sounds a lot better than just disappearing into the void without a trace.&lt;/p&gt;
&lt;p&gt;This begs the questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;what information to send&lt;/li&gt;
&lt;li&gt;how to compress/represent the information/data&lt;/li&gt;
&lt;li&gt;how to send it (including the &lt;a href="https://arxiv.org/pdf/1101.4968.pdf"&gt;transmission strategy&lt;/a&gt;: using lasers vs. omnidirectional radio transmitters, direction to point in, etc.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In fact, the approach for #2 (compression) affects #1 and #3. For example, we could decide to select more information for sending if we know it can be efficiently compressed, and if the compression algorithm allows fault-tolerant decompression, that might allow aliens to extract useful information even with incomplete reception of the transmitted data.&lt;/p&gt;
&lt;h1&gt;The compression tradeoff&lt;/h1&gt;
&lt;p&gt;We‚Äôd want to convey useful information on the &lt;strong&gt;essence&lt;/strong&gt; of humanity with &lt;strong&gt;lossy compression&lt;/strong&gt; (i.e. we aren‚Äôt able to perfectly recover the original data when decompressing). I speculate that the tradeoff between useful information and lossiness of compression may look something like the below, so we‚Äôd want to target the highest point in the curve.&lt;/p&gt;
&lt;p&gt;&lt;img alt="todo add alt text" src="https://miro.medium.com/max/20000/1*peVnP6QaPft--FpKzvLveA.png"&gt;(&lt;a href="https://docs.google.com/spreadsheets/d/1bvpLlxeYF_njHC4oPDhXIgC7bGO5ZLejPPKl9OxFGTw/edit#gid=0"&gt;spreadsheet for the above&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;As you increase lossiness, the information, when decompressed/recovered, becomes less true to the original data and thus less ‚Äúuseful,‚Äù but it allows for more efficient compression algorithms, which allows you to fit more usefulness into each bit. The definition of what is ‚Äúuseful‚Äù info about humanity is a philosophical debate which I won‚Äôt get into now.&lt;/p&gt;
&lt;h1&gt;Machine learning to the rescue&lt;/h1&gt;
&lt;p&gt;Embeddings (essentially, a list of numbers) generated by deep neural networks (e.g. &lt;a href="https://medium.com/@peacej2/generating-fake-k-pop-faces-part-1-6202dc27f0eb"&gt;autoencoders&lt;/a&gt; or language models such as &lt;a href="http://jalammar.github.io/illustrated-bert/"&gt;BERT&lt;/a&gt;) can be seen as a form of lossy compression (where the degree of compression can be arbitrarily chosen). For example, you can represent an image or the profile of a human with an embedding. As &lt;a href="https://arxiv.org/abs/1206.5538"&gt;representation learning&lt;/a&gt; techniques advance, perhaps we‚Äôll be able to accurately represent a human‚Äôs behavior/personality with an embedding (queue &lt;a href="https://www.youtube.com/watch?v=rYelEUVQ50g"&gt;Westworld theme song&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Via training, a neural network can figure out how to efficiently represent the essence of the information. Such an approach is &lt;a href="https://www.forbes.com/sites/nvidia/2019/02/11/accelerating-the-internet-with-ai-based-media-compression/#1a6508107760"&gt;already being used to reduce video download sizes&lt;/a&gt;. In the future, we‚Äôll have even better machine learning techniques to do this even more efficiently.&lt;/p&gt;
&lt;p&gt;Of course, we‚Äôll need to send not just the embeddings, but also the neural network parameters as well so that the aliens can make sense of the embeddings.&lt;/p&gt;
&lt;p&gt;The information that is represented isn‚Äôt limited to just words, images, and numbers. A generative neural network that can accurately generate random new virtual humans (i.e. it ‚Äúsamples‚Äù from a realistic distribution of human physique and behavior) or simulate human movement in cities may also be ‚Äúinformation‚Äù that we want to send.&lt;/p&gt;
&lt;h1&gt;It‚Äôs tÃ∂uÃ∂rÃ∂tÃ∂lÃ∂eÃ∂sÃ∂ models all the way down&lt;/h1&gt;
&lt;p&gt;Let‚Äôs get meta for a moment. Neural networks themselves are information. In fact, &lt;a href="https://arxiv.org/abs/1906.04358"&gt;even neural networks with randomly chosen parameters can perform well&lt;/a&gt;, which implies that the architecture of the network is also important information. Furthermore, a single neural network can be a lot of information. For example, &lt;a href="https://medium.com/@Synced/openai-unveils-175-billion-parameter-gpt-3-language-model-3d3f453124cd"&gt;OpenAI‚Äôs GPT-3 language model has 175 billion parameters&lt;/a&gt;. Hundreds of years from now, we might have models with quadrillions of parameters (which could‚Ä¶ simulate all of human civilization‚Ä¶?)&lt;/p&gt;
&lt;p&gt;So, we might want to send the aliens:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the parameters of a neural network compressed using another neural network&lt;/li&gt;
&lt;li&gt;a model which can design/train other models (although getting this to run on an alien‚Äôs hardware/software stack might be non-trivial)&lt;/li&gt;
&lt;li&gt;one of the above recursed indefinitely&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(BTW, &lt;a href="https://en.wikipedia.org/wiki/Turtles_all_the_way_down"&gt;see this&lt;/a&gt; if you didn‚Äôt get the joke about turtles üòä)&lt;/p&gt;
&lt;h1&gt;What would aliens do with the data?&lt;/h1&gt;
&lt;p&gt;Hard to say. Maybe they would benefit from some of our technology. Maybe they‚Äôd create a computer simulation of earth and humans living on it. Or maybe they‚Äôd using advanced bio-engineering to create living things resembling humans‚Ä¶ In any case, it would be better than no one ever knowing that humans existed.&lt;/p&gt;
&lt;h1&gt;This might be the most important thing we ever do&lt;/h1&gt;
&lt;p&gt;Do you want to prioritize big, long-term impact over short-term quick wins? If so, let‚Äôs extend the thinking by a few years (or millenia). &lt;strong&gt;After humanity perishes, our long-term impact will be essentially zero unless we communicate with extraterrestrial intelligence.&lt;/strong&gt; Unless, of course, we create robots that outlive us in a meaningful way‚Ä¶but even then, the physical robots may perish eventually due the sheer distance to inhabitable planets‚Ä¶ then, the only way to &lt;strong&gt;save&lt;/strong&gt; our legacy is via efficient transmission of information through space. Otherwise, &lt;strong&gt;the universe will be as if humans had never existed.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="todo add alt text" src="https://miro.medium.com/max/20000/1*7y_jTOIX7frtWVz5iSoBPQ.png"&gt;Image from &lt;a href="https://art.marcsimonetti.com/science-fiction"&gt;https://art.marcsimonetti.com/science-fiction&lt;/a&gt;&lt;/p&gt;</content><category term="machine learning"></category><category term="machine learning"></category><category term="futurism"></category><category term="computer science"></category></entry><entry><title>My Favorite Mind Blowing ML/AI Breakthroughs</title><link href="https://jerrychi.com/my-favorite-mind-blowing-mlai-breakthroughs.html" rel="alternate"></link><published>2019-02-10T00:00:00+09:00</published><updated>2019-02-10T00:00:00+09:00</updated><author><name>Jerry Chi</name></author><id>tag:jerrychi.com,2019-02-10:/my-favorite-mind-blowing-mlai-breakthroughs.html</id><summary type="html">&lt;p&gt;¬∑7 min read&lt;/p&gt;
&lt;p&gt;Compared to other fields, machine learning / artificial intelligence seems to have a much higher frequency of super-interesting developments these days. Things that make you say ‚Äúwow‚Äù or even ‚Äúwhat a time to be alive!‚Äù (as the creator of &lt;a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg"&gt;Two Minute Papers&lt;/a&gt; always says)&lt;/p&gt;
&lt;p&gt;Disclaimer: I‚Äôm not ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;p&gt;¬∑7 min read&lt;/p&gt;
&lt;p&gt;Compared to other fields, machine learning / artificial intelligence seems to have a much higher frequency of super-interesting developments these days. Things that make you say ‚Äúwow‚Äù or even ‚Äúwhat a time to be alive!‚Äù (as the creator of &lt;a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg"&gt;Two Minute Papers&lt;/a&gt; always says)&lt;/p&gt;
&lt;p&gt;Disclaimer: I‚Äôm not using any rigorous definition of ‚Äúmind-blowing‚Äù or ‚Äúbreakthrough‚Äù; it‚Äôs a casual list.. and I might use less rigorous terminology to make this post more accessible&lt;/p&gt;
&lt;h1&gt;Amazingly accurate estimates from seemingly unusable information&lt;/h1&gt;
&lt;h2&gt;Through-wall human pose estimation&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://rfpose.csail.mit.edu/"&gt;Website/video by MIT researchers, 2018&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="todo add alt text" src="https://miro.medium.com/max/20000/0*uqi7O3ByIKTsf6Ps.png"&gt;&lt;/p&gt;
&lt;p&gt;We can accurately estimate how a human on the other side of a wall is standing/sitting/walking just from perturbations in Wifi signals caused by that human.&lt;/p&gt;
&lt;h2&gt;Gauging materials‚Äô physical properties from video&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://news.mit.edu/2015/visual-microphone-identifies-structural-defects-0521"&gt;Article/video by MIT researchers, 2015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The researchers first &lt;a href="http://news.mit.edu/2014/algorithm-recovers-speech-from-vibrations-0804"&gt;demonstrated in 2014&lt;/a&gt; that they can e.g. reproduce human speech from video (with no audio) of a potato chip bag based on the vibrations. This part was done without machine learning. In 2015, they used machine learning to show that you can estimate the stiffness, elasticity, weight per unit area, etc. of materials just from a video (in some cases just the vibrations caused by the ordinary circulation of air was sufficient).&lt;/p&gt;
&lt;h2&gt;Estimating keystrokes from a smartphone next to the keyboard&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.sigmobile.org/mobicom/2015/papers/p142-liuA.pdf"&gt;Paper, 2015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="todo add alt text" src="https://miro.medium.com/max/2000/1*O9Kq4tclO75FZLiZVMkdDg.png"&gt;&lt;/p&gt;
&lt;p&gt;Researchers showed that with the audio recorded by a single, off-the-shelf smartphone placed next to a keyboard, one can estimate with &lt;strong&gt;94% accuracy&lt;/strong&gt; the individual keystrokes. Unlike previous approaches that used supervised deep learning with many microphones placed around the keyboard, this paper actually uses a relatively simple machine learning technique (K-means clustering) and &lt;strong&gt;unsupervised&lt;/strong&gt; learning.&lt;/p&gt;
&lt;h1&gt;Generative models&lt;/h1&gt;
&lt;h2&gt;Realistic face generation, style-mixing, and interpolation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1812.04948"&gt;Paper&lt;/a&gt;/&lt;a href="https://www.youtube.com/watch?v=kSLJriaOumA"&gt;video&lt;/a&gt; by NVIDIA researchers, 2018&lt;/p&gt;
&lt;p&gt;&lt;img alt="Image result for stylegan" src="https://miro.medium.com/proxy/0*eeFaGLx96mlbQcrK.gif"&gt;&lt;/p&gt;
&lt;p&gt;The researchers combined a new architecture with tons of GPUs to create extremely photo-realistic artificial faces that are interpolations between other faces or applications of the ‚Äústyle‚Äù of one face to another face. The work builds upon past work on Generative Adversarial Networks (GANs). GANs were invented in 2014 and have seen an explosion in research since then. The most basic concept of GANs is two neural networks dueling against each other (e.g. one that classifies images as ‚Äúreal‚Äù or ‚Äúfake‚Äù and a second neural network that generates images in a way that attempts to ‚Äútrick‚Äù the first neural network into wrongly classifying fake images as real‚Ä¶hence the second neural network is an ‚Äúadversary‚Äù to the first).&lt;/p&gt;
&lt;p&gt;In general, there is a lot of &lt;a href="https://github.com/yenchenlin/awesome-adversarial-machine-learning"&gt;awesome research&lt;/a&gt; about adversarial machine learning, which has been around for more than a decade. There are many creepy implications for cybersecurity etc. But I digress.&lt;/p&gt;
&lt;h2&gt;Teaching machines to draw&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://ai.googleblog.com/2017/04/teaching-machines-to-draw.html"&gt;Blog post by Google Brain, 2017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="todo add alt text" src="https://miro.medium.com/max/20000/0*m_S6mdQhp1Xz8G7V.png"&gt;Interpolation between 2 drawings&lt;/p&gt;
&lt;p&gt;My acquaintance &lt;a href="https://twitter.com/hardmaru"&gt;David Ha at Google Brain&lt;/a&gt; used a generative recurrent neural network (RNN) to make drawings that are vector-based graphics (I think of this as Adobe Illustrator except automated).&lt;/p&gt;
&lt;h2&gt;Transferring great dance moves to poor dancers&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://carolineec.github.io/everybody_dance_now/"&gt;Website&lt;/a&gt;/&lt;a href="https://www.youtube.com/watch?v=PCBTZh41Ris"&gt;video&lt;/a&gt; from UC Berkeley researchers, 2018&lt;/p&gt;
&lt;p&gt;Think ‚ÄúAuto-Tune for dancing.‚Äù Using pose estimation and generative adversarial training, the researchers were able to make a fake video of any real person (the ‚Äútarget‚Äù person) dancing with great dance skills. The required input was only:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a short video of someone with great dance skills dancing&lt;/li&gt;
&lt;li&gt;a few minutes of video of the target person dancing (typically poorly since most people suck at dancing)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also saw Jensen Huang, the CEO of NVIDIA, show a video (made with this technique) of himself dancing like Michael Jackson. I‚Äôm glad I attended the GPU Tech Conference, haha.&lt;/p&gt;
&lt;h1&gt;Reinforcement learning&lt;/h1&gt;
&lt;h2&gt;World models ‚Äî AI learning inside its own dream&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://worldmodels.github.io/"&gt;Website by Google Brain, 2018&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="todo add alt text" src="https://miro.medium.com/max/20000/0*t6x7EEUGlErd8nLb.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;Humans do not actually know or think about all the details of the world we live in. We behave based on the abstraction of the world that is in our heads. For example, if I ride on a bike, I don‚Äôt think of the gears/nuts/bolts of the bike; I just have a rough sense of where the wheels, seat, and handle are and how to interact with them. Why not use a similar approach for AI?&lt;/p&gt;
&lt;p&gt;This ‚Äúworld models‚Äù approach (again, created by David Ha et al) allows the ‚Äúagent‚Äù (e.g. an AI that controls a car in a racing game) to create a generative model of the world/environment around it which is a simplification/abstraction of the actual environment. So, you can think of the world model as a dream that lives in the head of the AI. Then the AI can train via reinforcement learning in this ‚Äúdream‚Äù to achieve better performance. So this approach is actually combining generative ML with reinforcement learning. By doing this, the researchers were able to achieve state-of-the-art performance on certain video game-playing tasks.&lt;/p&gt;
&lt;p&gt;[Update 2019/2/15] Building upon the above ‚Äúworld models‚Äù approach, Google just revealed &lt;a href="http://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html"&gt;PlaNet: Deep Planning Network for Reinforcement Learning&lt;/a&gt;, which achieved 5000% better data efficiency than previous approaches.&lt;/p&gt;
&lt;h2&gt;AlphaStar ‚Äî Starcraft II AI that beats the top pro players&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/"&gt;Blog post&lt;/a&gt;, &lt;a href="https://www.youtube.com/watch?v=cUTMhmVh1qs"&gt;e-sports-ish video&lt;/a&gt; by DeepMind (Google), 2019&lt;/p&gt;
&lt;p&gt;We‚Äôve come a long way from the &lt;a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol"&gt;historic Go matches between Lee Sedol and DeepMind‚Äôs AlphaGo&lt;/a&gt; that rocked the world, which was a mere 3 years ago in 2016 (check out the &lt;a href="https://www.netflix.com/jp-en/title/80190844"&gt;NetFlix documentary&lt;/a&gt;, which made some people cry). Then, it was even more amazing that AlphaZero in 2017 became better than AlphaGo at Go (and better than any other algorithm at chess, shogi AKA Japanese chess, etc.) despite not using any training data from human matches. But AlphaStar in 2019 is even &lt;strong&gt;more&lt;/strong&gt; amazing.&lt;/p&gt;
&lt;p&gt;Being a StarCraft fan myself since 1998, I can appreciate how the ‚Äú‚Ä¶need to balance short and long-term goals and adapt to unexpected situations‚Ä¶ poses a huge challenge.‚Äù It‚Äôs truly a difficult and complex game which requires understanding at multiple levels to play well. Research on Starcraft-playing algorithms have been ongoing since 2009.&lt;/p&gt;
&lt;p&gt;AlphaStar essentially used a combination of supervised learning (from human matches) and reinforcement learning (playing against itself) to achieve its results.&lt;/p&gt;
&lt;h1&gt;Humans training robots&lt;/h1&gt;
&lt;h2&gt;Teaching tasks to machines with a single human demonstration&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://news.developer.nvidia.com/new-ai-technique-helps-robots-work-alongside-humans/"&gt;Article&lt;/a&gt;/&lt;a href="https://www.youtube.com/watch?time_continue=1&amp;amp;v=B7ZT5oSnRys"&gt;video&lt;/a&gt; by NVIDIA researchers, 2018&lt;/p&gt;
&lt;p&gt;I can think of 3 typical approaches to teaching robots to do something, but all take a lot of time/labor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manually program the robot‚Äôs joint rotations etc. for each situation&lt;/li&gt;
&lt;li&gt;Let the robot try the task many, many times (reinforcement learning)&lt;/li&gt;
&lt;li&gt;Demonstrate a task to the robot many, many times&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Typically, one major criticism of deep learning is that it‚Äôs very costly to produce the millions of examples (data) that make the computer perform well. But increasingly, there are ways to not rely on such costly data.&lt;/p&gt;
&lt;p&gt;The researchers figured out a way for a robot arm to successfully perform a task (such as ‚Äúpick up the blocks and stack them so that they are in the order: red block, blue block, orange block‚Äù) based on a &lt;strong&gt;single&lt;/strong&gt; video of a &lt;strong&gt;single&lt;/strong&gt; human demonstration (a physical real human hand moving the blocks), even if the video was shot from a different angle. The algorithm actually generates a human-readable description of the task it plans to do, which is great for troubleshooting. The algorithm relies on object detection with pose estimation, synthetic training data generation, and simulation-to-reality transfer.&lt;/p&gt;
&lt;h1&gt;Unsupervised machine translation&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://code.fb.com/ai-research/unsupervised-machine-translation-a-novel-approach-to-provide-fast-accurate-translations-for-more-languages/"&gt;Blog post by Facebook AI Research, 2018&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Typically, you would need a huge training dataset of translated documents (e.g. professional translations of United Nations proceedings) to do machine translation well (i.e. &lt;strong&gt;supervised&lt;/strong&gt; learning). Of course, many topics and language pairs don‚Äôt have high-quality, plentiful training data. In this paper, researchers showed that it‚Äôs possible to use &lt;strong&gt;unsupervised&lt;/strong&gt; learning (i.e. using no translation data and just using unrelated corpuses of text in each language), it‚Äôs possible to reach the translation quality of state-of-the-art &lt;strong&gt;supervised&lt;/strong&gt; learning approaches. Wow.&lt;/p&gt;
&lt;p&gt;The basic idea is that, in any language, certain words/concepts will tend to appear in close proximity (e.g. ‚Äúfurry‚Äù and ‚Äúcat‚Äù). They describe this as ‚Äúembeddings of words in different languages share similar neighborhood structure.‚Äù I mean, OK, I get the idea, but it‚Äôs still mind-blowing that using this approach they can reach such high translation quality without training on translation datasets.&lt;/p&gt;
&lt;h1&gt;Closing&lt;/h1&gt;
&lt;p&gt;I hope this post made you more excited about developments in ML/AI, if you weren‚Äôt already. Maybe I‚Äôll write another similar post in a year from now. Please feel free to leave any thoughts/comments here or e-mail me at jerrychi123 [at] gmail.com.&lt;/p&gt;
&lt;p&gt;What a time to be alive! =D&lt;/p&gt;</content><category term="machine learning"></category><category term="machine learning"></category><category term="research"></category><category term="computer vision"></category><category term="unsupervised learning"></category></entry></feed>